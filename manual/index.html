<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <base data-ice="baseUrl" href="../">
  <title data-ice="title">Manual | causal-net</title>
  <link type="text/css" rel="stylesheet" href="css/style.css">
  <link type="text/css" rel="stylesheet" href="css/prettify-tomorrow.css">
  <script src="script/prettify/prettify.js"></script>
  <script src="script/manual.js"></script>
<link rel="stylesheet" href="./inject/css/0-pure-min.css"><link rel="stylesheet" href="./inject/css/0-causal-style.css"><script src="./inject/script/0-jquery-3.3.1.min.js"></script><script src="./inject/script/0-run_examples.js"></script></head>
<body class="layout-container manual-root manual-index" data-ice="rootContainer">

<header>
  <a href="./">Home</a>
  
  <a href="identifiers.html">Reference</a>
  <a href="source.html">Source</a>
  <a href="test.html" data-ice="testLink">Test</a>
  <div class="search-box">
  <span>
    <img src="./image/search.png">
    <span class="search-input-edge"></span><input class="search-input"><span class="search-input-edge"></span>
  </span>
    <ul class="search-result"></ul>
  </div>
</header>

<nav class="navigation" data-ice="nav"><div class="manual-toc-root">
  
<div data-ice="manual">
    <ul class="manual-toc">
      
    <li data-ice="manualNav" class="indent-h1" data-link="manual/introduction.html"><a href="manual/introduction.html#introduction" data-ice="link">Introduction</a></li>
<li data-ice="manualNav" class="indent-h2" data-link="manual/introduction.html"><a href="manual/introduction.html#pipeline-package" data-ice="link">Pipeline package</a></li>
<li data-ice="manualNav" class="indent-h1" data-link="manual/introduction.html"><a href="manual/introduction.html#sub-packages" data-ice="link">Sub-packages</a></li>
<li data-ice="manualNav" class="indent-h2" data-link="manual/introduction.html"><a href="manual/introduction.html#causal-net-core" data-ice="link">causal-net.core</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#causalnetcore" data-ice="link">causalNetCore</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#tensor" data-ice="link">Tensor</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#function" data-ice="link">Function</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#store" data-ice="link">Store</a></li>
<li data-ice="manualNav" class="indent-h2" data-link="manual/introduction.html"><a href="manual/introduction.html#causal-net-representation" data-ice="link">causal-net.representation</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#causalnetembedding" data-ice="link">causalNetEmbedding</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#universalembedding" data-ice="link">universalEmbedding</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#representationmixins" data-ice="link">RepresentationMixins</a></li>
<li data-ice="manualNav" class="indent-h2" data-link="manual/introduction.html"><a href="manual/introduction.html#causal-net-sampling" data-ice="link">causal-net.sampling</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#causalnetsampling" data-ice="link">causalNetSampling</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#samplingmixins" data-ice="link">SamplingMixins</a></li>
<li data-ice="manualNav" class="indent-h2" data-link="manual/introduction.html"><a href="manual/introduction.html#causal-net-models" data-ice="link">causal-net.models</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#causalnetmodels" data-ice="link">causalNetModels</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#supervisedmodelsmixins" data-ice="link">SupervisedModelsMixins</a></li>
<li data-ice="manualNav" class="indent-h2" data-link="manual/introduction.html"><a href="manual/introduction.html#causal-net-memcache" data-ice="link">causal-net.memcache</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#memdowncache" data-ice="link">memDownCache</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#memcachemixins" data-ice="link">MemCacheMixins</a></li>
<li data-ice="manualNav" class="indent-h2" data-link="manual/introduction.html"><a href="manual/introduction.html#causal-net-storage" data-ice="link">causal-net.storage</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#indexdbstorage" data-ice="link">indexDBStorage</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#storagemixins" data-ice="link">StorageMixins</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#csvfilemixins" data-ice="link">CSVFileMixins</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#pngfilemixins" data-ice="link">PNGFileMixins</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#textfilemixins" data-ice="link">TextFileMixins</a></li>
<li data-ice="manualNav" class="indent-h2" data-link="manual/introduction.html"><a href="manual/introduction.html#causal-net-utils" data-ice="link">causal-net.utils</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#platform" data-ice="link">platform</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#fetch" data-ice="link">fetch</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#png" data-ice="link">PNG</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#csv" data-ice="link">CSV</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#stream" data-ice="link">Stream</a></li>
<li data-ice="manualNav" class="indent-h3" data-link="manual/introduction.html"><a href="manual/introduction.html#assert" data-ice="link">assert</a></li>
</ul>
  </div>
<div data-ice="manual">
    <ul class="manual-toc">
      
    <li data-ice="manualNav" class="indent-h1" data-link="manual/streamProcessingText8.babel.node.js.html"><a href="manual/streamProcessingText8.babel.node.js.html" data-ice="link">Tutorials</a></li>
<li data-ice="manualNav" class="indent-h2" data-link="manual/streamProcessingText8.babel.node.js.html"><a href="manual/streamProcessingText8.babel.node.js.html#stream-processing-with-text8-data" data-ice="link">Stream processing with text8 data</a></li>
</ul>
  </div>
</div>
</nav>

<div class="content" data-ice="content"><div class="github-markdown">
  <div class="manual-user-index" data-ice="manualUserIndex"><p><strong><em>This project is immature and under active development. Contents will be updated rapidly</em></strong></p>
<h1 id="portable-deep-learning-models-with-causality">Portable deep learning models with Causality</h1><p><img src="./manual/asset/coffee-main.jpg" alt="Photo on Unsplash"></p>
<p>Causality is a free and open source javascript library that allows building isomorphic machine learning pipeline. Roundly speaking, your trained model can be deployed on client&apos;s devices via web environment without re-piping your code. </p>
<p>On top of Tensorflowjs, our set of reusable components handle data preprocessing, infer data representation, visualizing, training and evaluation on both node and web environment with the same APIs. Thus reduce engineering efforts for making production AI services. By using the same language, developers can simplify development setup, mitigate the communication cost, better coding pattern and share more ideas. </p>
<p>Moreover, with AI models are loaded as client&apos; devices for performing inference, personal or sensitive data is not exposed to the service providers. We also invest in ensemble learning and the recent federated learning approach for distributed training while preserving data privacy without requiring any global data storage. </p>
<p>Researchers can utilize built-in datasets and the prebuilt pipelines to prototype new model ideas and make research results easy to review, present and reproduce. We hope developers and researchers can find this project a meaningful work to contribute and collaborate to push forward a new class of affordable, transparent deep learning services. </p>
<p>The commercial version of this library, Moderator, is our effort for moderating social network contents heading to protecting community culture. The AI moderator, which is built up by community voted training data, transparently prevent bad contents from propagating, and re-ranking relevant contents prior to client views without revealing any personal preference. The Causality, Moderator alongside with React Social Network are the ideas from our startup, Red Gold, for building a smarter social network with community culture respect and transparent AI moderator.</p>
</div>

  

  <div class="manual-cards">
    
  <div class="manual-card-wrap" data-ice="cards">
      <div class="manual-card">
        <div data-ice="card"><h1>Sub-packages</h1><h2>causal-net.core</h2><p>This package provides:</p><h3>causalNetCore</h3><ul>
<li>Allow acess to core function and core tensor instance.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { causalNetCore } from &apos;causal-net.core&apos;;
console.log(causalNetCore.CoreTensor);
console.log(causalNetCore.CoreFunction);
</code>
</code></pre><p><a href="./manual/./asset/examples/core.babel.js">Run code</a></p><h3>Tensor</h3><ul>
<li>Primitive class for composing Tensor based class. This class is based on <a href="https://js.tensorflow.org/">tensorflowjs</a></li>
</ul><h3>Function</h3><ul>
<li>Primitive class for composing Function based class. This class is based on <a href="https://ramdajs.com/">Ramda</a></li>
</ul><h3>Store</h3><ul>
<li>Primivtive class for composing Store base class. This class is based on <a href="https://www.npmjs.com/package/levelup">levelup</a></li>
</ul><h2>causal-net.representation</h2><p>This module provide representation instances and representation mixins</p><h3>causalNetEmbedding</h3><ul>
<li>Provide methods for transforming tokens or representing sentence into single vector.</li>
</ul><p>Node</p><pre><code class="lang-javascript"><code class="source-code prettyprint">import { causalNetEmbedding } from &apos;causal-net.representation&apos;;
import { termLogger } from &apos;causal-net.log&apos;;
(async ()=&gt;{
    const configLink = &apos;../../datasets/WordVec_EN/&apos;;
    await causalNetEmbedding.connect(configLink, true);
    //first time transform will find on storage cache
    let vecs = await causalNetEmbedding.transform([&apos;this&apos;, &apos;is&apos;, &apos;test&apos;]);
    for(let vec of vecs){
        termLogger.log({ vec });
    }
    //second time transform will find on memory cache
    vecs = await causalNetEmbedding.transform([&apos;this&apos;, &apos;is&apos;, &apos;test&apos;]);
    for(let vec of vecs){
        termLogger.log({ vec });
    }
    //return the tensor representing sentence
    let sentVec = await causalNetEmbedding.sentenceEncode([ [&apos;this&apos;, &apos;is&apos;, &apos;test&apos;] ]);
    sentVec.print();
})().catch(err=&gt;{
    console.error(err);
});</code>
</code></pre><p><a href="./manual/./asset/examples/causalNetEmbedding.babel.node.js">Run code</a></p><h3>universalEmbedding</h3><ul>
<li>Provide methods for transforming tokens or representing sentence into single vector based <a href="https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder">use</a></li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { universalEmbedding, Log } from &apos;causal-net.representation&apos;;
import { termLogger } from &apos;causal-net.log&apos;;
(async ()=&gt;{
    // termLogger.groupBegin();
    await universalEmbedding.connect();
    // termLogger.groupEnd();
    let sentVec = await universalEmbedding.sentenceEncode([ &apos;this is test&apos; ])
    sentVec.print();
})();</code>
</code></pre><p><a href="./manual/./asset/examples/universalEmbedding.babel.js">Run code</a></p><h3>RepresentationMixins</h3><ul>
<li>Mixins for mix with Pipeline class or dataset class.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { RepresentationMixins, causalNetEmbedding } from &apos;causal-net.representation&apos;;
import { platform } from &apos;causal-net.utils&apos;;
import { Tensor } from &apos;causal-net.core&apos;;
const PipeLineConfigure = {
    Representation: {
        Embedding: causalNetEmbedding,
        EmbeddingConfig: &apos;../../datasets/WordVec_EN/&apos;,
    }
}
class SimplePipeline extends platform.mixWith(Tensor, [RepresentationMixins]){
    constructor(configure){
        super();
        this.setRepresentationByConfig(configure);
    }
}
let pipeline = new SimplePipeline(PipeLineConfigure);
pipeline.connect();
console.log(pipeline.Representation);</code>
</code></pre><p><a href="./manual/./asset/examples/embeddingMixins.babel.node.js">Run code</a></p><h2>causal-net.sampling</h2><p>This causal-net.sampling is a sub-module for <a href="https://red-gold.github.io/causality-docs/">causality</a> project.
This module provide sampling instance and sampling mixins</p><h3>causalNetSampling</h3><ul>
<li>Provide sampling instance with various sampling methods.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { causalNetSampling } from &apos;causal-net.sampling&apos;;
import {termLogger as Logger} from &apos;causal-net.log&apos;;
let numSamples = 4;
let idSize = 10;//id list: [0,1,2,3,4,5,6,7,8,9]
Logger.log(causalNetSampling.subSampling(numSamples, idSize));

numSamples = 4;
let positiveSampleId = [0, 1];
//ids: [0, 1, 2, 3];
let probIds = [0.9, 0.9, 0.3, 0.7];
let samples = causalNetSampling.negSampling(numSamples, positiveSampleId, probIds);
termLogger.log({ samples });</code>
</code></pre><p><a href="./manual/./asset/examples/causalNetSampling.babel.js">Run code</a></p><h3>SamplingMixins</h3><ul>
<li>Mixins Mixins for mix with Pipeline class or dataset class.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { SamplingMixins, causalNetSampling } from &apos;causal-net.sampling&apos;;
import { Platform } from &apos;causal-net.utils&apos;;
import { Tensor, Function } from &apos;causal-net.core&apos;;
console.log(causalNetSampling instanceof Function);
class SimplePipeline extends Platform.mixWith(Tensor, [SamplingMixins]){
    constructor(){
        super();
        this.Sampling = causalNetSampling;
    }
}
let pipeline = new SimplePipeline();
console.log(pipeline.Sampling);</code>
</code></pre><p><a href="./manual/./asset/examples/sampling.mixins.babel.js">Run code</a></p><h2>causal-net.models</h2><h3>causalNetModels</h3><ul>
<li>causalNetModels provides common used models: </li>
</ul><p>Classification models</p><pre><code class="lang-javascript"><code class="source-code prettyprint">import { Log, Models, CausalNet } from &apos;../../src/index&apos;;
const { causalNetModels } = Models;
const { termLogger } = Log;
let inputs = [[0.52, 1.12,  0.77],
              [0.88, -1.08, 0.15],
              [0.52, 0.06, -1.30],
              [0.74, -2.49, 1.39]];
let targets = [[0, 1], [0, 1], [0, 1], [0, 1]];
const _NetConfig = {
    HyperParameters: {SampleSize: 4},
    NumClasses: 2,
    Pipeline:[
        {   Name:&apos;dense&apos;, Type: &apos;Tensor&apos;, 
            Parameters: { Weight: [3, 2], Bias: [2]  },
            Flow: [ { Op: &apos;dot&apos;, Parameter: &apos;Weight&apos;, Args: [] },
                    { Op: &apos;add&apos;, Parameter: &apos;Bias&apos;,  Args: [] } ] 
        },
        {   Name:&apos;PipeOutput&apos;, Type: &apos;Tensor&apos;, 
            Flow: [ { Op: &apos;reshape&apos;, Args: [[&apos;$SampleSize&apos;, -1]] } ] 
        } 
    ],
    Model:  causalNetModels.classification() };

console.log({NetConfig: _NetConfig});
let parameters = {};

let causalNet = new CausalNet(_NetConfig, parameters);

(async ()=&gt;{
    const DoBatchTrainSampleGenerator = (epochIdx)=&gt;([{idx:0, batchSize:4, data: [inputs, targets]}]);
    let logTrain = await causalNet.train(DoBatchTrainSampleGenerator, 20);
    termLogger.log(logTrain);
    const DoBatchTestSampleGenerator = ()=&gt;([{idx:0, batchSize:4, data: [inputs, targets]}]);
    let testResult = await causalNet.accuracyTest(DoBatchTestSampleGenerator);
    termLogger.log({testResult});
    await causalNet.saveParams(&apos;save_model.model&apos;);
    await causalNet.loadParams(&apos;save_model.model&apos;);
    testResult = await causalNet.accuracyTest(DoBatchTestSampleGenerator);
    termLogger.log({testResult});
    testResult = await causalNet.ensembleAccuracyTest(DoBatchTestSampleGenerator, [&apos;save_model.model&apos;]);
    termLogger.log({testResult});
    testResult = await causalNet.accuracyTest(DoBatchTestSampleGenerator, [&apos;save_model.model&apos;]);
    termLogger.log({testResult});
})().catch(err=&gt;{
    console.error({err});
});</code>
</code></pre><p><a href="./manual/./asset/examples/classification.babel.js">Run code</a></p><h3>SupervisedModelsMixins</h3><ul>
<li>Mixins for mix with Pipeline class for supervised models.</li>
</ul><p>[EXAMPLE  ERROR! /home/huynhnguyen/github/causality/packages/causality-layers/DESCRIPTION.md]</p><h2>causal-net.memcache</h2><h3>memDownCache</h3><ul>
<li>memDownCache provides wrapper for <a href>memdown</a> caching.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import {memDownCache} from &apos;causal-net.memcache&apos;;
import {termLogger} from &apos;causal-net.log&apos;;

(async ()=&gt;{
    await memDownCache.setItem(123, &apos;1223adfa&apos;);
    termLogger.log({getItem: await memDownCache.getItem(123)});
})();
</code>
</code></pre><p><a href="./manual/./asset/examples/memDownCache.babel.js">Run code</a></p><h3>MemCacheMixins</h3><ul>
<li>Mixins for mix with Pipeline class for memcache.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import {memDownCache, MemCacheMixins} from &apos;causal-net.memcache&apos;;
import {termLogger} from &apos;causal-net.log&apos;;

import { platform } from &apos;causal-net.utils&apos;;
import { Tensor, Store } from &apos;causal-net.core&apos;;

class SimplePipeline extends platform.mixWith(Tensor, [MemCacheMixins]){
    constructor(){
        super();
        this.MemCache = memDownCache;
    }
}
let pipeline = new SimplePipeline();
termLogger.log(pipeline.MemCache instanceof Store);</code>
</code></pre><p><a href="./manual/./asset/examples/memCache.mixins.babel.js">Run code</a></p><h2>causal-net.storage</h2><p>This module provides:</p><h3>indexDBStorage</h3><ul>
<li>The isomorphic high performance key-value storage based on indexDB.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { indexDBStorage } from &apos;causal-net.storage&apos;;
(async ()=&gt;{
    await indexDBStorage.writeFile(&apos;/temp&apos;,&apos;12345&apos;);
    let content  = await indexDBStorage.readFile(&apos;/temp&apos;);
    console.log({content});

    //get file list
    let listFiles = await indexDBStorage.getFileList(&apos;/&apos;);
    console.log({listFiles});

    //fetch png image and save pixel data into file
    const url = &apos;https://avatars3.githubusercontent.com/u/43268620?s=200&amp;v=4&apos;;
    await indexDBStorage.fetchPNGFile(url, &apos;icon&apos;);
    const pixelArray = await indexDBStorage.readPNGFile(&apos;icon&apos;);
    console.log({ pixelArray });

    let ops = [
        { type: &apos;put&apos;, key: &apos;temp&apos;, value: &apos;123445&apos; },
        { type: &apos;del&apos;, key: &apos;temp&apos; }];
    //batch does not support &apos;get&apos; type
    let batchResult = await indexDBStorage.batch(ops);
    console.log({batchResult});
})().catch(err=&gt;{
    console.error(err);
});
</code>
</code></pre><p><a href="./manual/./asset/examples/storage.babel.js">Run code</a></p><h3>StorageMixins</h3><ul>
<li>Mixins storage for mix with Pipeline class.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { StorageMixins, indexDBStorage } from &apos;causal-net.storage&apos;;
import { platform } from &apos;causal-net.utils&apos;;
import { Tensor, Store } from &apos;causal-net.core&apos;;

class SimplePipeline extends platform.mixWith(Tensor, [StorageMixins]){
    constructor(){
        super();
        this.Storage = indexDBStorage;
    }
}
let pipeline = new SimplePipeline();
console.log(pipeline.Storage instanceof Store);</code>
</code></pre><p><a href="./manual/./asset/examples/storage.mixins.babel.js">Run code</a></p><h3>CSVFileMixins</h3><ul>
<li>Mixins for read/write/fetch CSV file. </li>
</ul><h3>PNGFileMixins</h3><ul>
<li>Mixins for read/write/fetch PNG file.</li>
</ul><h3>TextFileMixins</h3><ul>
<li>Mixins for read/write/fetch Text file.</li>
</ul><h2>causal-net.utils</h2><p>This module provides:</p><h3>platform</h3><ul>
<li>Enhanced isomorphic mixins with corresponding platform (node|web).</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { assert } from &apos;causal-net.utils&apos;;
assert.seemMatchSample([2,2,3], [1,2,3], &apos;validate sample&apos;);
assert.seemMatchSample(&apos;sample text&apos;, &apos;pattern text&apos;, &apos;validate sample&apos;);
assert.seemMatchSample( { &apos;text&apos; : &apos;pattern text 1&apos;, &apos;number&apos; : 1123 }, 
                        { &apos;text&apos; : &apos;pattern text&apos;, &apos;number&apos; : 1123 } , &apos;validate sample&apos;);
try{
    assert.seemMatchSample([&apos;2&apos;,2,3], [1,2,3], &apos;validate sample&apos;);
}
catch(err){
    //error due to mismatch schema
    console.log(err.message);
};
class A{};
let a = new A();
assert.beInstanceOf(a, A);
try{
    assert.beInstanceOf(&apos;1&apos;, A);
}
catch(err){
    console.log(err.message);
}
</code>
</code></pre><p><a href="./manual/./asset/examples/assert.babel.js">Run code</a></p><h3>fetch</h3><ul>
<li>isomorphic fetch.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import {fetch, Stream, PNGUtils} from &apos;causal-net.utils&apos;;
(async ()=&gt;{
    let link = &apos;https://avatars3.githubusercontent.com/u/43268620?s=200&amp;v=4&apos;;
    let content = await fetch.fetchData(link);
    console.log({&apos;content length&apos;: content.length});
});

</code>
</code></pre><p><a href="./manual/./asset/examples/fetch.babel.js">Run code</a></p><h3>PNG</h3><ul>
<li>isomorphic PNG parser.</li>
</ul><p>Web/Node:</p><pre><code class="lang-javascript"><code class="source-code prettyprint">import { pngUtils } from &apos;causal-net.utils&apos;;
(async ()=&gt;{
    const link = &apos;https://avatars3.githubusercontent.com/u/43268620?s=200&amp;v=4&apos;;
    let fetchedData = await pngUtils.fetchPNG(link);
    console.log(fetchedData.length);
})();</code>
</code></pre><p><a href="./manual/./asset/examples/png.babel.js">Run code</a></p><p>Node:</p><pre><code class="lang-javascript"><code class="source-code prettyprint">import { pngUtils } from &apos;causal-net.utils&apos;;
(async ()=&gt;{
    let data = await pngUtils.readPNG(&apos;../../datasets/icon.png&apos;);
    console.log(data.length);
    pngUtils.writePNG(data, [200, 200, 4], &apos;./out.png&apos;);
})();
</code>
</code></pre><p><a href="./manual/./asset/examples/png.babel.node.js">Run code</a></p><h3>CSV</h3><ul>
<li>isomorphic CSV parser.</li>
</ul><p>Node:</p><pre><code class="lang-javascript"><code class="source-code prettyprint">import { csvUtils } from &apos;causal-net.utils&apos;;
(async ()=&gt;{
    let data = await csvUtils.readCSV(&apos;../../datasets/credict.csv&apos;);
    console.log(data);
})();
</code>
</code></pre><p><a href="./manual/./asset/examples/csv.babel.node.js">Run code</a></p><h3>Stream</h3><ul>
<li>isomorphic Stream with Readable, Writeable, Duplex.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { stream } from &apos;causal-net.utils&apos;;

let reader = stream.makeReadable();

const TranformFn = (chunkData, chunkEncoding, afterTransformFn) =&gt;{
    chunkData.x = (chunkData.x+1.5);
    let event = null;
    afterTransformFn(event, chunkData);
};
let transformer = stream.makeTransform(TranformFn);

const WriteFn = (chunkData, chunkEncoding, callback) =&gt;{
    console.log({chunkData});
    callback();
};
let writer = stream.makeWritable(WriteFn);

reader.pipe(transformer).pipe(writer);
//write random int for every 100 ms    
setInterval(() =&gt; {
    reader.push({ x: Math.random() });
}, 100);
</code>
</code></pre><p><a href="./manual/./asset/examples/stream.babel.js">Run code</a></p><h3>assert</h3><ul>
<li>Enhanced isomorphic assert with schema learnt from example.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">import { assert } from &apos;causal-net.utils&apos;;
assert.seemMatchSample([2,2,3], [1,2,3], &apos;validate sample&apos;);
assert.seemMatchSample(&apos;sample text&apos;, &apos;pattern text&apos;, &apos;validate sample&apos;);
assert.seemMatchSample( { &apos;text&apos; : &apos;pattern text 1&apos;, &apos;number&apos; : 1123 }, 
                        { &apos;text&apos; : &apos;pattern text&apos;, &apos;number&apos; : 1123 } , &apos;validate sample&apos;);
try{
    assert.seemMatchSample([&apos;2&apos;,2,3], [1,2,3], &apos;validate sample&apos;);
}
catch(err){
    //error due to mismatch schema
    console.log(err.message);
};
class A{};
let a = new A();
assert.beInstanceOf(a, A);
try{
    assert.beInstanceOf(&apos;1&apos;, A);
}
catch(err){
    console.log(err.message);
}
</code>
</code></pre><p><a href="./manual/./asset/examples/assert.babel.js">Run code</a></p></div>
        <a data-ice="link" href="manual/introduction.html#sub-packages"></a>
      </div>
    </div>
<div class="manual-card-wrap" data-ice="cards">
      <div class="manual-card">
        <div data-ice="card"><h1>Tutorials</h1><h2>Stream processing with text8 data</h2><p>Input raw text8 corpus file and return the occurent number of each tokens in corpus.</p><pre><code class="lang-javascript"><code class="source-code prettyprint">import * as Preprocessing from &apos;causal-net.preprocessing&apos;;
import * as Log from &apos;causal-net.log&apos;;
import * as Utils from &apos;causal-net.utils&apos;;
import * as Storage from &apos;causal-net.storage&apos;;
import * as fs from &apos;fs&apos;;
var { indexDBStorage } = Storage;
var { stream } = Utils;
var { termLogger } = Log;
var { nlpPreprocessing, tokenizerEN } = Preprocessing;</code>
</code></pre><pre><code><code class="source-code prettyprint">&apos;use strict&apos;</code>
</code></pre><p>create stream process</p><ul>
<li>read chunks from file.</li>
<li>transform each chunk.</li>
<li>write transformed chunk into new files.</li>
</ul><pre><code class="lang-javascript"><code class="source-code prettyprint">var remainingChars = &apos;&apos;, wordFreqCount = {}, lineIndex = 0;
function tranformFn(chunkData, chunkEncoding, afterTransformFn){
    let sampleText = chunkData + remainingChars;
    let sampleLines = sampleText.split(&apos;\n&apos;);
    let transformedData = [];
    for(let line of sampleLines){
        let tokens = tokenizerEN.tokenize(line);
        wordFreqCount = nlpPreprocessing.wordFreqCount(tokens, wordFreqCount);
        lineIndex += 1;
        transformedData.push({lineIndex, tokens});
    }
    afterTransformFn(null, transformedData);
};
var transformer = stream.makeTransform(tranformFn);

function writeTokens(transformedData, chunkEncoding, afterWriteFn){
    const WriteTokensToFile = async (transformedData)=&gt;{
        for(let {lineIndex, tokens} of transformedData){
//             console.log({lineIndex});
            await indexDBStorage.writeFile(`/corpus/line_${lineIndex}`, JSON.stringify(tokens));
        }
    }
    WriteTokensToFile(transformedData).then(()=&gt;{
        afterWriteFn();
    })
}
var writer = stream.makeWritable(writeTokens);
var characterCount = 0;
(async ()=&gt;{
    var corpusReader = fs.createReadStream(&apos;../datasets/text8/text8.txt&apos;);
    const CorpusStreamer = stream.makePipeline([corpusReader, transformer, writer], (data)=&gt;{
        characterCount += data.length;
    });
    termLogger.groupBegin(&apos;stream performance&apos;);
    let result = await CorpusStreamer;
    termLogger.groupEnd()
    termLogger.log({ result, characterCount } );
})();</code>
</code></pre><pre><code><code class="source-code prettyprint">stream performance: begin at Fri Mar 15 2019 16:42:45 GMT+0700 (Indochina Time)
stream performance: end after 8514 (ms)
{ result: &apos;Success&apos;, characterCount: 100000000 }</code>
</code></pre><pre><code class="lang-javascript"><code class="source-code prettyprint">termLogger.log({&apos;show 100 items&apos;: Object.entries(wordFreqCount).slice(0,100)});</code>
</code></pre><pre><code><code class="source-code prettyprint">{ &apos;show 100 items&apos;:
   [ [ &apos;anarchism&apos;, 303 ],
     [ &apos;originated&apos;, 572 ],
     [ &apos;as&apos;, 131819 ],
     [ &apos;a&apos;, 325895 ],
     [ &apos;term&apos;, 7220 ],
     [ &apos;of&apos;, 593676 ],
     [ &apos;abuse&apos;, 563 ],
     [ &apos;first&apos;, 28809 ],
     [ &apos;used&apos;, 22736 ],
     [ &apos;against&apos;, 8431 ],
     [ &apos;early&apos;, 10172 ],
     [ &apos;working&apos;, 2270 ],
     [ &apos;class&apos;, 3412 ],
     [ &apos;radicals&apos;, 116 ],
     [ &apos;including&apos;, 9630 ],
     [ &apos;the&apos;, 1061363 ],
     [ &apos;diggers&apos;, 25 ],
     [ &apos;english&apos;, 11868 ],
     [ &apos;revolution&apos;, 2029 ],
     [ &apos;and&apos;, 416615 ],
     [ &apos;sans&apos;, 68 ],
     [ &apos;culottes&apos;, 6 ],
     [ &apos;french&apos;, 8736 ],
     [ &apos;whilst&apos;, 481 ],
     [ &apos;is&apos;, 183158 ],
     [ &apos;still&apos;, 7378 ],
     [ &apos;in&apos;, 372203 ],
     [ &apos;pejorative&apos;, 114 ],
     [ &apos;way&apos;, 6432 ],
     [ &apos;to&apos;, 316375 ],
     [ &apos;describe&apos;, 1352 ],
     [ &apos;any&apos;, 11804 ],
     [ &apos;act&apos;, 3502 ],
     [ &apos;that&apos;, 109508 ],
     [ &apos;violent&apos;, 653 ],
     [ &apos;means&apos;, 4165 ],
     [ &apos;destroy&apos;, 466 ],
     [ &apos;organization&apos;, 2374 ],
     [ &apos;society&apos;, 4067 ],
     [ &apos;it&apos;, 73335 ],
     [ &apos;has&apos;, 37865 ],
     [ &apos;also&apos;, 44358 ],
     [ &apos;been&apos;, 25381 ],
     [ &apos;taken&apos;, 3043 ],
     [ &apos;up&apos;, 12446 ],
     [ &apos;positive&apos;, 1254 ],
     [ &apos;label&apos;, 646 ],
     [ &apos;by&apos;, 111829 ],
     [ &apos;self&apos;, 2879 ],
     [ &apos;defined&apos;, 2449 ],
     [ &apos;anarchists&apos;, 203 ],
     [ &apos;word&apos;, 5678 ],
     [ &apos;derived&apos;, 1701 ],
     [ &apos;from&apos;, 72865 ],
     [ &apos;greek&apos;, 4577 ],
     [ &apos;without&apos;, 5660 ],
     [ &apos;archons&apos;, 10 ],
     [ &apos;ruler&apos;, 617 ],
     [ &apos;chief&apos;, 2130 ],
     [ &apos;king&apos;, 7457 ],
     [ &apos;political&apos;, 6967 ],
     [ &apos;philosophy&apos;, 2758 ],
     [ &apos;belief&apos;, 1572 ],
     [ &apos;rulers&apos;, 687 ],
     [ &apos;are&apos;, 76523 ],
     [ &apos;unnecessary&apos;, 146 ],
     [ &apos;should&apos;, 5113 ],
     [ &apos;be&apos;, 61283 ],
     [ &apos;abolished&apos;, 399 ],
     [ &apos;although&apos;, 9286 ],
     [ &apos;there&apos;, 22706 ],
     [ &apos;differing&apos;, 231 ],
     [ &apos;interpretations&apos;, 395 ],
     [ &apos;what&apos;, 8581 ],
     [ &apos;this&apos;, 58827 ],
     [ &apos;refers&apos;, 1570 ],
     [ &apos;related&apos;, 3535 ],
     [ &apos;social&apos;, 4307 ],
     [ &apos;movements&apos;, 1002 ],
     [ &apos;advocate&apos;, 331 ],
     [ &apos;elimination&apos;, 216 ],
     [ &apos;authoritarian&apos;, 185 ],
     [ &apos;institutions&apos;, 1021 ],
     [ &apos;particularly&apos;, 2881 ],
     [ &apos;state&apos;, 12905 ],
     [ &apos;anarchy&apos;, 109 ],
     [ &apos;most&apos;, 25562 ],
     [ &apos;use&apos;, 14011 ],
     [ &apos;does&apos;, 5220 ],
     [ &apos;not&apos;, 44030 ],
     [ &apos;imply&apos;, 257 ],
     [ &apos;chaos&apos;, 331 ],
     [ &apos;nihilism&apos;, 42 ],
     [ &apos;or&apos;, 68948 ],
     [ &apos;anomie&apos;, 7 ],
     [ &apos;but&apos;, 35356 ],
     [ &apos;rather&apos;, 4605 ],
     [ &apos;harmonious&apos;, 28 ],
     [ &apos;anti&apos;, 3103 ],
     [ &apos;place&apos;, 5345 ] ] }</code>
</code></pre><p>After preprocessing, data is saved into files under <code>/copus/</code> folder</p><pre><code class="lang-javascript"><code class="source-code prettyprint">(async ()=&gt;{
    termLogger.groupBegin(&apos;get list of preprocessing files&apos;)
    let listFiles = await indexDBStorage.getFileList(&apos;/corpus/&apos;);
    termLogger.groupEnd()
    termLogger.groupBegin(&apos;read one file from indexDB&apos;)
    let tokens = await indexDBStorage.readFile(listFiles[0]);
    termLogger.groupEnd()
    termLogger.log([ listFiles.length , JSON.parse(tokens).length]);
})()    </code>
</code></pre><pre><code><code class="source-code prettyprint">get list of preprocessing files: begin at Fri Mar 15 2019 16:42:56 GMT+0700 (Indochina Time)
get list of preprocessing files: end after 194 (ms)
read one file from indexDB: begin at Fri Mar 15 2019 16:42:56 GMT+0700 (Indochina Time)
read one file from indexDB: end after 0 (ms)
[ 3228, 1293 ]</code>
</code></pre><pre><code class="lang-javascript"><code class="source-code prettyprint"></code>
</code></pre></div>
        <a data-ice="link" href="manual/streamProcessingText8.babel.node.js.html"></a>
      </div>
    </div>
</div>
</div>
</div>

<footer class="footer">
  Generated by <a href="https://esdoc.org">ESDoc<span data-ice="esdocVersion">(1.1.0)</span><img src="./image/esdoc-logo-mini-black.png"></a>
</footer>

<script src="script/search_index.js"></script>
<script src="script/search.js"></script>
<script src="script/pretty-print.js"></script>
<script src="script/inherited-summary.js"></script>
<script src="script/test-summary.js"></script>
<script src="script/inner-link.js"></script>
<script src="script/patch-for-local.js"></script>
</body>
</html>
